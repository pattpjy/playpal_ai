{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install langchain_experimental\n",
    "!pip install lxml\n",
    "!pip install beautifulsoup4\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function parse_worksheet takes a BeautifulSoup object doc as an input and extracts information from it to create a dictionary of activities. The dictionary called activity with four key-value pairs: title, activity_contents, categories, thumbnail pair with value extracting from target website by finding targeted class name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def parse_worksheet(doc):\n",
    "  soup = BeautifulSoup(doc)\n",
    "  try:\n",
    "    activity_title = soup.h1.get_text()\n",
    "\n",
    "    try:\n",
    "      activity_contents = soup.find(class_='worksheet-module_contentDetailContainer_3Pou6').next_element.get_text()\n",
    "    except AttributeError:\n",
    "            print(\"Error: Couldn't find activity_contents element.\")\n",
    "            print(\"HTML content of the soup object:\")\n",
    "            print(soup.prettify())\n",
    "            return None\n",
    "\n",
    "    categories = {'brand':[], 'subject':[]}\n",
    "\n",
    "    cat_title = soup.find_all(class_=re.compile('CategoryTree-module_values'))\n",
    "\n",
    "    result1 = cat_title[0].find_all(class_=re.compile(\"Tag-module_tagBody\"))\n",
    "\n",
    "    for div in result1:\n",
    "        cat_list = div.next_element.get_text();\n",
    "        categories['brand'].append(cat_list)\n",
    "\n",
    "    result2 = cat_title[1].find_all(class_=re.compile(\"Tag-module_tagBody\"))\n",
    "\n",
    "    for div in result2:\n",
    "        cat_list = div.next_element.get_text();\n",
    "        categories['subject'].append(cat_list)\n",
    "\n",
    "    thumbnail = soup.find(class_=\"worksheet-module_thumbnail_3_tCk\").next_element.next_element.get('src')\n",
    "    activity = {'title' :activity_title, 'activity_contents': activity_contents, 'categories':categories, 'thumbnail':thumbnail }\n",
    "    return activity\n",
    "  except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code uses the Requests library to make HTTP requests and the BeautifulSoup library to parse HTML responses. It retrieves a list of activities from the Education.com website, and then extracts information about each activity, such as its title, contents, categories, and thumbnail image URL. a for loop that iterates over each result in the results list, but only up to 50 results will be processed at a time.  This line pauses the script for 4 seconds, so it doesn't overwhelm the Education.com website with too many requests.\n",
    "urls[result['url']] = True - This line stores the URL of the current activity in the urls dictionary, so we can avoid duplicates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import truncate\n",
    "import requests\n",
    "import time\n",
    "\n",
    "urls = {}\n",
    "activity_array = []\n",
    "page_num = 2\n",
    "while page_num < 13:\n",
    "\n",
    "  url_query = f'https://content.education.com/search?path=%2Fresources%2F%3Fsort%3DdateCreated%26page%3D{page_num}&onlyValidUrls=false'\n",
    "  response = requests.get(url_query).json()\n",
    "  print(f'got response from page {page_num}')\n",
    "  page_num += 1\n",
    "  results = response['results']\n",
    "  for result in results[0:50]:\n",
    "    if result['url'] not in urls:\n",
    "      web_doc = requests.get(f'https://www.education.com{result[\"url\"]}').text\n",
    "      print(result['url'])\n",
    "      # make soup\n",
    "      activity_obj = parse_worksheet(web_doc)\n",
    "      activity_obj['url'] = result['url']\n",
    "      urls[result['url']] = True\n",
    "      activity_array.append(activity_obj)\n",
    "      time.sleep(4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to write and read CSV files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('activities.csv', 'w', newline='') as file:\n",
    "  field = [\"title\", \"activity_contents\", \"categories\", \"url\",\"thumbnail\"]\n",
    "  writer = csv.DictWriter(file, fieldnames=field)\n",
    "  writer.writeheader()\n",
    "  for activity in activity_array:\n",
    "        writer.writerow(activity)\n",
    "\n",
    "\n",
    "with open('activities.csv', 'r') as file:\n",
    "    for line in file:\n",
    "        print(line.strip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
